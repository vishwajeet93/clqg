---
src_vocab: 
dst_vocab: 
src_gen: 
dst_gen: 
src_vocab_size_a: 39799
dst_vocab_size_a: 39799
src_vocab_size_b: 17278
dst_vocab_size_b: 17278
src_vocab_size: 0
dst_vocab_size: 0
hidden_units: 500
scale_embedding: True
attention_dropout_rate: 0.0
residual_dropout_rate: 0.2
num_blocks: 6
num_heads: 10
binding_embedding: False
kl_weight: 0.00002
enc_layer_indep: 4
enc_layer_share: 1
dec_layer_indep: 4
dec_layer_share: 1
generate_maxlen: 50
lock_enc_embed: False
vari_emb_scale: 0.00
multi_channel_encoder: True
train_ratio: 0

train:
    devices: '2'
    src_path: 
    dst_path: 
    src_path_1: 
    dst_path_1: 
    tokens_per_batch:  5000
    max_length: 80
    num_epochs: 15
    logdir: 'out/48'
    save_freq: 100
    summary_freq: 10
    disp_freq: 10
    grads_clip: 5
    optimizer: 'adam_decay'
    learning_rate: 0.00001
    gan_learning_rate: 0.00001
    learning_rate_warmup_steps: 10000
    warm_steps: 1000
    label_smoothing: 0.1
    batch_size: 64
    shared_embedding: False
    shuffle_k: 5
    src_pretrain_wordemb_path: 
    dst_pretrain_wordemb_path: 
    src_more: True
    restore_partial: False
    restore_embed: True
    restore_decoder: False
    restore_decoder_embed: False
    decoder_logdir: 'out/32'

test:
    mode: 'bb'
    src_path: 
    dst_path: 
    ori_dst_path: 
    output_path:    
    batch_size: 32
    max_target_length: 200
    beam_size: 4
    lp_alpha: 0.6
    devices: '2'
